<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="keyword"  content="">
    <link rel="shortcut icon" href="/img/favicon.ico">

    <title>
        
        论文阅读-GANs用于离散序列生成 - undefined
        
    </title>

    <!-- Custom CSS -->
    
<link rel="stylesheet" href="/css/aircloud.css">

    
<link rel="stylesheet" href="/css/gitment.css">

    <!--<link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">-->
    <link href="//at.alicdn.com/t/font_620856_pl6z7sid89qkt9.css" rel="stylesheet" type="text/css">
    <!-- ga & ba script hoook -->
    <script></script>
<meta name="generator" content="Hexo 5.3.0"></head>

<body>

<div class="site-nav-toggle" id="site-nav-toggle">
    <button>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
    </button>
</div>

<div class="index-about">
    <i> 不被理想束缚的生活 </i>
</div>

<div class="index-container">
    
    <div class="index-left">
        
<div class="nav" id="nav">
    <div class="avatar-name">
        <div class="avatar radius">
            <img src="/img/avatar.jpg" />
        </div>
        <div class="name">
            <i>Anthony</i>
        </div>
    </div>
    <div class="contents" id="nav-content">
        <ul>
            <li >
                <a href="/">
                    <i class="iconfont icon-shouye1"></i>
                    <span>HOME</span>
                </a>
            </li>
            <li >
                <a href="/tags">
                    <i class="iconfont icon-biaoqian1"></i>
                    <span>TAGS</span>
                </a>
            </li>
            <li >
                <a href="/archives">
                    <i class="iconfont icon-guidang2"></i>
                    <span>ARCHIVES</span>
                </a>
            </li>
            <li >
                <a href="/about/">
                    <i class="iconfont icon-guanyu2"></i>
                    <span>ABOUT</span>
                </a>
            </li>
            
        </ul>
    </div>
    
        <div id="toc" class="toc-article">
    <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%80%E4%BB%8B"><span class="toc-text">简介</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#gumbel-softmax%E5%88%86%E5%B8%83"><span class="toc-text">Gumbel-softmax分布</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%A6%BB%E6%95%A3%E5%BA%8F%E5%88%97%E7%9A%84%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="toc-text">离散序列的递归神经网络</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%B9%E6%8A%97%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B"><span class="toc-text">对抗生成模型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8gs%E5%88%86%E5%B8%83"><span class="toc-text">使用GS分布</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%AE%97%E6%B3%951%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C"><span class="toc-text">算法1：生成对抗网络</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C"><span class="toc-text">实验</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AD%A6%E4%B9%A0%E4%B8%80%E4%B8%AAcfg"><span class="toc-text">学习一个CFG</span></a></li></ol></li></ol>
</div>
    
</div>


<div class="search-field" id="search-field">
    <div class="search-container">
        <div class="search-input">
            <span id="esc-search"> <i class="icon-fanhui iconfont"></i></span>
            <input id="search-input"/>
            <span id="begin-search">search</span>
        </div>
        <div class="search-result-container" id="search-result-container">

        </div>
    </div>
</div>

        <div class="index-about-mobile">
            <i> 不被理想束缚的生活 </i>
        </div>
    </div>
    
    <div class="index-middle">
        <!-- Main Content -->
        


<div class="post-container">
    <div class="post-title">
        论文阅读-GANs用于离散序列生成
    </div>

    <div class="post-meta">
        <span class="attr">Post：<span>2018-01-28 12:20:10</span></span>
        
        <span class="attr">Tags：/
        
        <a class="tag" href="/tags/#GANs" title="GANs">GANs</a>
        <span>/</span>
        
        <a class="tag" href="/tags/#Gumbel-softmax分布" title="Gumbel-softmax分布">Gumbel-softmax分布</a>
        <span>/</span>
        
        
        </span>
        <span class="attr">Visit：<span id="busuanzi_value_page_pv"></span>
</span>
</span>
    </div>
    <div class="post-content ">
        <p><strong>篇名</strong>：<em>GANS for Sequences of Discrete Elements with the Gumbel-softmax Distribution</em></p>
<p><strong>概要中提出的问题</strong>：当目标是生成离散元素构成的序列时 GAN 是存在限制的。</p>
<p><strong>出现问题的原因</strong> ：是来自服从离散对象分布的样本，例如多项式关于分布参数是不可区分的。</p>
<p><strong>解决方法</strong>：作者提出使用 Gumbel-softmax 分布可以避免这个问题，该分布是对 softmax 函数参数化的多项分布的连续逼近。</p>
<p><strong>本文所做的工作</strong>：评估基于 GS 输出分布的递归神经网络的GAN在生成离散元素组成的序列这一任务中的性能如何。</p>
<a id="more"></a>
<h3 id="简介">简介</h3>
<p>GAN通过从鉴别器产生的样本后向传播到生成器来工作。如果产生的样本是连续的，例如图像生成的例子，这是可行的。但是如果大量数据以离散的形式存在，比如文本中的句子，以 SMILE语言编码的分子等。在这些情况下，离散数据是不可微分的（由高等数学的知识，可微一定连续，连续不一定可微，所以不连续一定不可微），反向传播的梯度总是0。</p>
<p>使用独热编码表示离散数据。这样就可以从多项分布中采样，其概率由softmax函数的输出给出。</p>
<p>用一个简单的例子来说明独热编码。例如有三个特征：</p>
<p>性别：[“男”，“女”] 爱好：[“篮球”，“足球”，“羽毛球”，“排球”]</p>
<p>国家：[“中国”，“美国”，“英国”，“俄罗斯”，“法国”]</p>
<p>对于某样本[“女”，“羽毛球”，“法国”]，用独热编码表示就是[01 0010 00001]。</p>
<p>何为softmax函数？</p>
<p>对于二分类问题，我们一般使用sigmoid函数将输入映射到 (0,1) 的区间中，从而得到某个类别的概率。推广到多类问题，我们使用softmax函数对输出的值归一化为概率值。</p>
<p>例如，假设输入数据是维度为 <span class="math inline">\(d\)</span> 的向量<span class="math inline">\(\textbf {h}\)</span>，那么经过softmax函数的输出也是一个 <span class="math inline">\(d\)</span>维度的向量 ，里面<span class="math inline">\(\textbf {p}\)</span>的值都在0到1之间，也就是概率值。所以理解为一个归一化的指数函数：</p>
<p><span class="math display">\[
{
[s o f t \max (h)]_{i}=\frac{e^{h_{i}}}{\sum_{j=1}^{d} e^{z_{j}}} \tag{1.1}
}
\]</span></p>
<p>其中$ i (1, d) $ ；</p>
<p>观察上述公式，还可以得到：</p>
<p><span class="math display">\[
{
\sum_{i=1}^{d}[s o f t \max (h)]_{i}=1 \tag{1.2}
}
\]</span> 个人通俗理解就是，先用指数函数 $ y=e^{x} $ 作用于 <span class="math inline">\(C\)</span> 维输入向量中分量的每个值，得到一串新值。再将这些新值加起来。用每个新值除以这个和就是经过softmax函数处理后对应的输出向量分量的对应值。</p>
<p>现在又提出了在离散序列上训练 GAN 的另一种方法。 该方法将离散序列的生成建模为强化学习中的随机策略，并通过直接执行梯度策略更新来绕过生成器区分问题。</p>
<h4 id="gumbel-softmax分布">Gumbel-softmax分布</h4>
<p>上面我已经介绍了 softmax函数，然后引入 Gumbel-softmax分布： <span class="math display">\[
{
y = onehot \left(\arg \max _{i}\left(h_{i}+g_{i}\right)\right) \tag{1.3}
}
\]</span> 其中 $ g_{i} $ 是独立的并且遵循 Gumbel分布，具有零位和单位尺度。 <span class="math display">\[
{
y=\operatorname{soft} \max (1 / \Gamma(h+g)) \tag{1.4}
}
\]</span> <span class="math inline">\(\Gamma\)</span>是一个逆向温度参数。当它趋于0时，由公式（1.4）生成的样本和公式（1.3）生成的样本有着相同的分布。而当它趋于无穷时，样本总是一致的概率向量。对于<span class="math inline">\({\Gamma}\)</span>的正值和有限值，由（1.4）生成的样本相对于是平<span class="math inline">\(\textbf {h}\)</span>滑和可微的。</p>
<p>公式（1.4）的概率分布就叫Gumbel-softmax分布。一个基于离散数据的GAN可以用（1.4）来训练了，从一些比较大的<span class="math inline">\(\Gamma\)</span>开始，然后在训练期间将其回零。</p>
<h4 id="离散序列的递归神经网络">离散序列的递归神经网络</h4>
<p>这个部分描述的是怎样建立一个能够从随机的噪音样本中生成文本的GAN模型。将给出一个简单的算法。</p>
<p><span class="math display">\[
{
 S \rightarrow x\|S+S\| S-S\|S * S\| S / S \tag{1.5} 
}
\]</span> 上面这个公式用来描述学习生成简单的单变量算术序列。两竖线用来划分语法的可能产生。</p>
<p>生成模型基于LSTM循环神经网络，它被训练用来在每个时间步预测一个隐藏状态的向量 <span class="math inline">\(\textbf {h}\)</span>，然后再对这个向量使用softmax函数归一化。训练结束后，网络通过从softmax分布中取样来生成数据。</p>
<p>训练LSTM模型以预测未来特征的一种方法是通过最大似然估计（MLE）将softmax分布与输入数据的独热编码进行匹配。构建一个离散序列的生成模型，通过LSTM进行采样来完成。生成模型以一个样本对为输入，有效地替换了初始细胞和隐藏状态。生成器通过连续地将其预测作为输入反馈到下面的LSTM单元来构建序列。目标是设计一种方法来训练这个生成器来产生真实的离散序列。</p>
<p><img src="/images/GANS_for_Sequences_of_Discrete_Elements/pic1-1.png"></p>
<p align="center">
图 1.1 一个经典的LSTM模型
</p>
<p>上图是一个经典的LSTM模型，每个LSTM单元（蓝色盒子）根据过去看到的输入进行预测，然后这个预测被用作下一个单元的输入，以此类推。</p>
<p><img src="/images/GANS_for_Sequences_of_Discrete_Elements/pic1-2.png"></p>
<p align="center">
图 1.2 离散序列的生成模型
</p>
<p>上图是离散序列的生成模型。一开始画一对样本并将它们送入网络，代替初始单元状态<span class="math inline">\(C_{0}\)</span> 和隐藏状态<span class="math inline">\(h_{0}\)</span> 。训练好的网络取这些样本并且使用它们生成一个初始特征，这个生成的特征被送到LSTM的下一个单元作为输入，以此类推。</p>
<h3 id="对抗生成模型">对抗生成模型</h3>
<p>给出一个由<span class="math inline">\(n\)</span>个独立同分布的数据点组成的集合，它们服从<span class="math inline">\(d\)</span>维分布<span class="math inline">\(p(x)\)</span>。对抗模型的目标就是学习一个<span class="math inline">\(q(x)\)</span>分布，该分布能精确接近 <span class="math inline">\(p(x)\)</span> 分布。生成对抗模型的架构是迫使<span class="math inline">\(q(x)\)</span>生成真实的样本点。首先，学习一个将服从简单已知分布的样本（例如均匀或高斯分布）转换为接近<span class="math inline">\(p(x)\)</span>的样本的模型，称之为生成器 <em>G</em> 。我们定义<span class="math inline">\(q(x):=G(\textbf{z})\)</span>，<span class="math inline">\(\textbf{z}\)</span>服从（0,1）均匀分布。 <strong>这段话的意思就是说生成器的随机输入向量 z 服从均匀分布（也可以是高斯分布或者其他简单分布），我们的目标就是要通过生成器<em>G</em>的作用将其变为一个十分接近真实数据 <em>p(x)</em> 分布的分布 <em>q(x)</em> ，显然 <em>q(x)</em> 分布相对来说应该比 <em>z</em> 初始分布复杂得多。</strong> 其次，鉴别器的是将任何真实的<span class="math inline">\(d\)</span>维向量作为输入，并且它能预测输入是否服从<span class="math inline">\(p(x)\)</span>的概率。同时生成器也被训练以愚弄鉴别器。一开始，鉴别器能够很容易区别真假数据，但是随着训练的不断进行生成器采用来自鉴别器发出的信号决定如何生成更真实的数据。最终，生成器生成的数据太过逼真以至于鉴别器会对生成数据是否真实给出一个随意的猜测。以上就是 GAN的核心思想，虽然在本文中提到，但我再顺便回顾加深一下。</p>
<h4 id="使用gs分布">使用<em>GS</em>分布</h4>
<p>G和D分别采用服从参数<em>Θ</em>和<em>Φ</em>的LSTM。目的是通过采样输入<span class="math inline">\(x\)</span>和生成点<span class="math inline">\(z\)</span>学习<em>G</em>和<em>D</em>，并且最小化<em>G</em>和<em>D</em>更新参数<em>Θ</em>和<em>Φ</em>的可微分的损失函数。不幸的是，采样生成点<span class="math inline">\(z\)</span>对于隐藏态<span class="math inline">\(h\)</span>是不可微的。所以需要使用公式（1.4）提出的策略。步骤在下面的算法中阐述，这个算法的目标是最小化<span class="math inline">\(q(z)\)</span>和<span class="math inline">\(p(x)\)</span>之间的KL散度。</p>
<h5 id="算法1生成对抗网络">算法1：生成对抗网络</h5>
<p>1：服从 <span class="math inline">\(p(x)\)</span> 分布的数据集 <span class="math inline">\(\left\lbrace x_{1},\ldots x_{n} \right \rbrace\)</span></p>
<p>2：生成器采用携带参数 <em>Θ</em> 的LSTM网络</p>
<p>3：鉴别器采用携带参数 <em>Φ</em> 的LSTM网络</p>
<p>4：一直循环迭代直到收敛</p>
<p>{</p>
<p style="text-indent:2em">
4.1：小批量样本输入集<em>B</em>，<em>B</em>中样本个数为 <em>m</em> ，即 <span class="math inline">\(\left \lbrace x_{B_{1}}, \ldots x_{B_{m}} \right \rbrace\)</span>
</p>
<p style="text-indent:2em">
4.2：样本噪声<em>N</em> : <span class="math inline">\(\left \lbrace z_{N_{1}}, \ldots z_{N_{m}} \right \rbrace\)</span>
</p>
<p style="text-indent:2em">
4.3：更新鉴别器参数 <em>Φ</em>
</p>
<p style="text-indent:2em">
4.4：更新生成器参数 <em>Θ</em>
</p>
<p>}</p>
<h3 id="实验">实验</h3>
<p><img src="/images/GANS_for_Sequences_of_Discrete_Elements/pic1-3.png"></p>
<p align="center">
图 1.3 生成loss和判别loss的变化
</p>
<p>上图是训练过程中生成损失和鉴别损失随迭代次数的变化。理想情况下鉴别器的损失应当提高而生成器的损失应当减小正如生成器在接近真实数据时表现得更好。（a）图是使用GS温度训练的神经网络。（b）图和前一张图设定一样但是将生成样本的大小扩大到1000，可以看到这张图中鉴别器的损失有小于生成器的损失了。(c) 图仅改变了输入向量温度值，可以看到生成器的损失在几乎所有迭代下是大于鉴别器的损失的。（d）只将随机噪声引入隐藏状态并且允许网络学习一个初始的细胞状态。</p>
<h4 id="学习一个cfg">学习一个<em>CFG</em></h4>
<p><img src="/images/GANS_for_Sequences_of_Discrete_Elements/pic1-4.png"></p>
<p align="center">
图 1.4 MLE模型生成的结果
</p>
<p>上图中第一幅图是MLE模型生成的文本。（a）到（d）对应实验部分第一张图的四个GAN模型生成文本的样例。每一行都是来自任意模型的样本，每一行包含12个特征（如果少于12个特征则用空格把缺少的特征补上）。我们将MLE LSTM作为GAN LSTM的参考。可以观察到，（a）图中第4,10,17行显示样本十分接近训练数据。</p>
<p>最后，作者认为结合最近GANs的进展，如使用变分散最小化训练GANs或通过密度比估计可以进一步的改善它。</p>

        
        <br />
        <div id="comment-container">
        </div>
        <div id="disqus_thread"></div>

        <div id="lv-container">
        </div>

    </div>
</div>

    </div>
</div>


<footer class="footer">
    <ul class="list-inline text-center">
        
        

        

        

        

        

    </ul>
    
    <p>
        <span id="busuanzi_container_site_pv">
            <span id="busuanzi_value_site_pv"></span>PV
        </span>
        <span id="busuanzi_container_site_uv">
            <span id="busuanzi_value_site_uv"></span>UV
        </span>
        Created By <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>  Theme <a target="_blank" rel="noopener" href="https://github.com/aircloud/hexo-theme-aircloud">AirCloud</a></p>
		<div class="translate-style">繁/简：<a id="translateLink" href="javascript:translatePage();">繁体</a></div>
</footer>

<script type="text/javascript" src="/js/tw_cn.js"></script>
<script type="text/javascript">
var defaultEncoding = 2; //网站编写字体是否繁体，1-繁体，2-简体
var translateDelay = 0; //延迟时间,若不在前, 要设定延迟翻译时间, 如100表示100ms,默认为0
var cookieDomain = "https://tding.top/"; //Cookie地址, 一定要设定, 通常为你的网址
var msgToTraditionalChinese = "繁体"; //此处可以更改为你想要显示的文字
var msgToSimplifiedChinese = "简体"; //同上，但两处均不建议更改
var translateButtonId = "translateLink"; //默认互换id
translateInitilization();
</script>



<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>

<script>
    // We expose some of the variables needed by the front end
    window.hexo_search_path = ""
    window.hexo_root = "/"
    window.isPost = true
</script>
<script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script>

<script src="/js/index.js"></script>

<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




</html>
