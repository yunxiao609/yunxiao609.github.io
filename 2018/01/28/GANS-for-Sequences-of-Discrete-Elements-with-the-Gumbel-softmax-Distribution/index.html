<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>论文阅读-GANs用于离散序列生成 | 筠筱的博客</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="篇名：GANS for Sequences of Discrete Elements with the Gumbel-softmax Distribution 概要中提出的问题：当目标是生成离散元素构成的序列时 GAN 是存在限制的。 出现问题的原因 ：是来自服从离散对象分布的样本，例如多项式关于分布参数是不可区分的。 解决方法：作者提出使用 Gumbel-softmax 分布可以避免这个问">
<meta property="og:type" content="article">
<meta property="og:title" content="论文阅读-GANs用于离散序列生成">
<meta property="og:url" content="http://example.com/2018/01/28/GANS-for-Sequences-of-Discrete-Elements-with-the-Gumbel-softmax-Distribution/index.html">
<meta property="og:site_name" content="筠筱的博客">
<meta property="og:description" content="篇名：GANS for Sequences of Discrete Elements with the Gumbel-softmax Distribution 概要中提出的问题：当目标是生成离散元素构成的序列时 GAN 是存在限制的。 出现问题的原因 ：是来自服从离散对象分布的样本，例如多项式关于分布参数是不可区分的。 解决方法：作者提出使用 Gumbel-softmax 分布可以避免这个问">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/images/GANS_for_Sequences_of_Discrete_Elements/pic1-1.png">
<meta property="og:image" content="http://example.com/images/GANS_for_Sequences_of_Discrete_Elements/pic1-2.png">
<meta property="og:image" content="http://example.com/images/GANS_for_Sequences_of_Discrete_Elements/pic1-3.png">
<meta property="og:image" content="http://example.com/images/GANS_for_Sequences_of_Discrete_Elements/pic1-4.png">
<meta property="article:published_time" content="2018-01-28T04:20:10.000Z">
<meta property="article:modified_time" content="2020-12-24T01:32:30.595Z">
<meta property="article:author" content="John Doe">
<meta property="article:tag" content="GANs">
<meta property="article:tag" content="Gumbel-softmax分布">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/images/GANS_for_Sequences_of_Discrete_Elements/pic1-1.png">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 5.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">筠筱的博客</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">不被理想束缚的生活</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">主页</a>
        
          <a class="main-nav-link" href="/archives">归档</a>
        
          <a class="main-nav-link" href="/about">关于</a>
        
          <a class="main-nav-link" href="/links">友链</a>
        
      </nav>
      <nav id="sub-nav">
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-GANS-for-Sequences-of-Discrete-Elements-with-the-Gumbel-softmax-Distribution" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2018/01/28/GANS-for-Sequences-of-Discrete-Elements-with-the-Gumbel-softmax-Distribution/" class="article-date">
  <time class="dt-published" datetime="2018-01-28T04:20:10.000Z" itemprop="datePublished">2018-01-28</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90/">文本生成</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      论文阅读-GANs用于离散序列生成
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p><strong>篇名</strong>：<em>GANS for Sequences of Discrete Elements with the Gumbel-softmax Distribution</em></p>
<p><strong>概要中提出的问题</strong>：当目标是生成离散元素构成的序列时 GAN 是存在限制的。</p>
<p><strong>出现问题的原因</strong> ：是来自服从离散对象分布的样本，例如多项式关于分布参数是不可区分的。</p>
<p><strong>解决方法</strong>：作者提出使用 Gumbel-softmax 分布可以避免这个问题，该分布是对 softmax 函数参数化的多项分布的连续逼近。</p>
<p><strong>本文所做的工作</strong>：评估基于 GS 输出分布的递归神经网络的GAN在生成离散元素组成的序列这一任务中的性能如何。</p>
<a id="more"></a>
<h3 id="简介">简介</h3>
<p>GAN通过从鉴别器产生的样本后向传播到生成器来工作。如果产生的样本是连续的，例如图像生成的例子，这是可行的。但是如果大量数据以离散的形式存在，比如文本中的句子，以 SMILE语言编码的分子等。在这些情况下，离散数据是不可微分的（由高等数学的知识，可微一定连续，连续不一定可微，所以不连续一定不可微），反向传播的梯度总是0。</p>
<p>使用独热编码表示离散数据。这样就可以从多项分布中采样，其概率由softmax函数的输出给出。</p>
<p>用一个简单的例子来说明独热编码。例如有三个特征：</p>
<p>性别：[“男”，“女”] 爱好：[“篮球”，“足球”，“羽毛球”，“排球”]</p>
<p>国家：[“中国”，“美国”，“英国”，“俄罗斯”，“法国”]</p>
<p>对于某样本[“女”，“羽毛球”，“法国”]，用独热编码表示就是[01 0010 00001]。</p>
<p>何为softmax函数？</p>
<p>对于二分类问题，我们一般使用sigmoid函数将输入映射到 (0,1) 的区间中，从而得到某个类别的概率。推广到多类问题，我们使用softmax函数对输出的值归一化为概率值。</p>
<p>例如，假设输入数据是维度为 <span class="math inline">\(d\)</span> 的向量<span class="math inline">\(\textbf {h}\)</span>，那么经过softmax函数的输出也是一个 <span class="math inline">\(d\)</span>维度的向量 ，里面<span class="math inline">\(\textbf {p}\)</span>的值都在0到1之间，也就是概率值。所以理解为一个归一化的指数函数：</p>
<p><span class="math display">\[
{
[s o f t \max (h)]_{i}=\frac{e^{h_{i}}}{\sum_{j=1}^{d} e^{z_{j}}} \tag{1.1}
}
\]</span></p>
<p>其中$ i (1, d) $ ；</p>
<p>观察上述公式，还可以得到：</p>
<p><span class="math display">\[
{
\sum_{i=1}^{d}[s o f t \max (h)]_{i}=1 \tag{1.2}
}
\]</span> 个人通俗理解就是，先用指数函数 $ y=e^{x} $ 作用于 <span class="math inline">\(C\)</span> 维输入向量中分量的每个值，得到一串新值。再将这些新值加起来。用每个新值除以这个和就是经过softmax函数处理后对应的输出向量分量的对应值。</p>
<p>现在又提出了在离散序列上训练 GAN 的另一种方法。 该方法将离散序列的生成建模为强化学习中的随机策略，并通过直接执行梯度策略更新来绕过生成器区分问题。</p>
<h4 id="gumbel-softmax分布">Gumbel-softmax分布</h4>
<p>上面我已经介绍了 softmax函数，然后引入 Gumbel-softmax分布： <span class="math display">\[
{
y = onehot \left(\arg \max _{i}\left(h_{i}+g_{i}\right)\right) \tag{1.3}
}
\]</span> 其中 $ g_{i} $ 是独立的并且遵循 Gumbel分布，具有零位和单位尺度。 <span class="math display">\[
{
y=\operatorname{soft} \max (1 / \Gamma(h+g)) \tag{1.4}
}
\]</span> <span class="math inline">\(\Gamma\)</span>是一个逆向温度参数。当它趋于0时，由公式（1.4）生成的样本和公式（1.3）生成的样本有着相同的分布。而当它趋于无穷时，样本总是一致的概率向量。对于<span class="math inline">\({\Gamma}\)</span>的正值和有限值，由（1.4）生成的样本相对于是平<span class="math inline">\(\textbf {h}\)</span>滑和可微的。</p>
<p>公式（1.4）的概率分布就叫Gumbel-softmax分布。一个基于离散数据的GAN可以用（1.4）来训练了，从一些比较大的<span class="math inline">\(\Gamma\)</span>开始，然后在训练期间将其回零。</p>
<h4 id="离散序列的递归神经网络">离散序列的递归神经网络</h4>
<p>这个部分描述的是怎样建立一个能够从随机的噪音样本中生成文本的GAN模型。将给出一个简单的算法。</p>
<p><span class="math display">\[
{
 S \rightarrow x\|S+S\| S-S\|S * S\| S / S \tag{1.5} 
}
\]</span> 上面这个公式用来描述学习生成简单的单变量算术序列。两竖线用来划分语法的可能产生。</p>
<p>生成模型基于LSTM循环神经网络，它被训练用来在每个时间步预测一个隐藏状态的向量 <span class="math inline">\(\textbf {h}\)</span>，然后再对这个向量使用softmax函数归一化。训练结束后，网络通过从softmax分布中取样来生成数据。</p>
<p>训练LSTM模型以预测未来特征的一种方法是通过最大似然估计（MLE）将softmax分布与输入数据的独热编码进行匹配。构建一个离散序列的生成模型，通过LSTM进行采样来完成。生成模型以一个样本对为输入，有效地替换了初始细胞和隐藏状态。生成器通过连续地将其预测作为输入反馈到下面的LSTM单元来构建序列。目标是设计一种方法来训练这个生成器来产生真实的离散序列。</p>
<p><img src="/images/GANS_for_Sequences_of_Discrete_Elements/pic1-1.png"></p>
<p align="center">
图 1.1 一个经典的LSTM模型
</p>
<p>上图是一个经典的LSTM模型，每个LSTM单元（蓝色盒子）根据过去看到的输入进行预测，然后这个预测被用作下一个单元的输入，以此类推。</p>
<p><img src="/images/GANS_for_Sequences_of_Discrete_Elements/pic1-2.png"></p>
<p align="center">
图 1.2 离散序列的生成模型
</p>
<p>上图是离散序列的生成模型。一开始画一对样本并将它们送入网络，代替初始单元状态<span class="math inline">\(C_{0}\)</span> 和隐藏状态<span class="math inline">\(h_{0}\)</span> 。训练好的网络取这些样本并且使用它们生成一个初始特征，这个生成的特征被送到LSTM的下一个单元作为输入，以此类推。</p>
<h3 id="对抗生成模型">对抗生成模型</h3>
<p>给出一个由<span class="math inline">\(n\)</span>个独立同分布的数据点组成的集合，它们服从<span class="math inline">\(d\)</span>维分布<span class="math inline">\(p(x)\)</span>。对抗模型的目标就是学习一个<span class="math inline">\(q(x)\)</span>分布，该分布能精确接近 <span class="math inline">\(p(x)\)</span> 分布。生成对抗模型的架构是迫使<span class="math inline">\(q(x)\)</span>生成真实的样本点。首先，学习一个将服从简单已知分布的样本（例如均匀或高斯分布）转换为接近<span class="math inline">\(p(x)\)</span>的样本的模型，称之为生成器 <em>G</em> 。我们定义<span class="math inline">\(q(x):=G(\textbf{z})\)</span>，<span class="math inline">\(\textbf{z}\)</span>服从（0,1）均匀分布。 <strong>这段话的意思就是说生成器的随机输入向量 z 服从均匀分布（也可以是高斯分布或者其他简单分布），我们的目标就是要通过生成器<em>G</em>的作用将其变为一个十分接近真实数据 <em>p(x)</em> 分布的分布 <em>q(x)</em> ，显然 <em>q(x)</em> 分布相对来说应该比 <em>z</em> 初始分布复杂得多。</strong> 其次，鉴别器的是将任何真实的<span class="math inline">\(d\)</span>维向量作为输入，并且它能预测输入是否服从<span class="math inline">\(p(x)\)</span>的概率。同时生成器也被训练以愚弄鉴别器。一开始，鉴别器能够很容易区别真假数据，但是随着训练的不断进行生成器采用来自鉴别器发出的信号决定如何生成更真实的数据。最终，生成器生成的数据太过逼真以至于鉴别器会对生成数据是否真实给出一个随意的猜测。以上就是 GAN的核心思想，虽然在本文中提到，但我再顺便回顾加深一下。</p>
<h4 id="使用gs分布">使用<em>GS</em>分布</h4>
<p>G和D分别采用服从参数<em>Θ</em>和<em>Φ</em>的LSTM。目的是通过采样输入<span class="math inline">\(x\)</span>和生成点<span class="math inline">\(z\)</span>学习<em>G</em>和<em>D</em>，并且最小化<em>G</em>和<em>D</em>更新参数<em>Θ</em>和<em>Φ</em>的可微分的损失函数。不幸的是，采样生成点<span class="math inline">\(z\)</span>对于隐藏态<span class="math inline">\(h\)</span>是不可微的。所以需要使用公式（1.4）提出的策略。步骤在下面的算法中阐述，这个算法的目标是最小化<span class="math inline">\(q(z)\)</span>和<span class="math inline">\(p(x)\)</span>之间的KL散度。</p>
<h5 id="算法1生成对抗网络">算法1：生成对抗网络</h5>
<p>1：服从 <span class="math inline">\(p(x)\)</span> 分布的数据集 <span class="math inline">\(\left\lbrace x_{1},\ldots x_{n} \right \rbrace\)</span></p>
<p>2：生成器采用携带参数 <em>Θ</em> 的LSTM网络</p>
<p>3：鉴别器采用携带参数 <em>Φ</em> 的LSTM网络</p>
<p>4：一直循环迭代直到收敛</p>
<p>{</p>
<p style="text-indent:2em">
4.1：小批量样本输入集<em>B</em>，<em>B</em>中样本个数为 <em>m</em> ，即 <span class="math inline">\(\left \lbrace x_{B_{1}}, \ldots x_{B_{m}} \right \rbrace\)</span>
</p>
<p style="text-indent:2em">
4.2：样本噪声<em>N</em> : <span class="math inline">\(\left \lbrace z_{N_{1}}, \ldots z_{N_{m}} \right \rbrace\)</span>
</p>
<p style="text-indent:2em">
4.3：更新鉴别器参数 <em>Φ</em>
</p>
<p style="text-indent:2em">
4.4：更新生成器参数 <em>Θ</em>
</p>
<p>}</p>
<h3 id="实验">实验</h3>
<p><img src="/images/GANS_for_Sequences_of_Discrete_Elements/pic1-3.png"></p>
<p align="center">
图 1.3 生成loss和判别loss的变化
</p>
<p>上图是训练过程中生成损失和鉴别损失随迭代次数的变化。理想情况下鉴别器的损失应当提高而生成器的损失应当减小正如生成器在接近真实数据时表现得更好。（a）图是使用GS温度训练的神经网络。（b）图和前一张图设定一样但是将生成样本的大小扩大到1000，可以看到这张图中鉴别器的损失有小于生成器的损失了。(c) 图仅改变了输入向量温度值，可以看到生成器的损失在几乎所有迭代下是大于鉴别器的损失的。（d）只将随机噪声引入隐藏状态并且允许网络学习一个初始的细胞状态。</p>
<h4 id="学习一个cfg">学习一个<em>CFG</em></h4>
<p><img src="/images/GANS_for_Sequences_of_Discrete_Elements/pic1-4.png"></p>
<p align="center">
图 1.4 MLE模型生成的结果
</p>
<p>上图中第一幅图是MLE模型生成的文本。（a）到（d）对应实验部分第一张图的四个GAN模型生成文本的样例。每一行都是来自任意模型的样本，每一行包含12个特征（如果少于12个特征则用空格把缺少的特征补上）。我们将MLE LSTM作为GAN LSTM的参考。可以观察到，（a）图中第4,10,17行显示样本十分接近训练数据。</p>
<p>最后，作者认为结合最近GANs的进展，如使用变分散最小化训练GANs或通过密度比估计可以进一步的改善它。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2018/01/28/GANS-for-Sequences-of-Discrete-Elements-with-the-Gumbel-softmax-Distribution/" data-id="ckjjl2fdf00025olaexpscpco" data-title="论文阅读-GANs用于离散序列生成" class="article-share-link">Share</a>
      
      
        <a href="/2018/01/28/GANS-for-Sequences-of-Discrete-Elements-with-the-Gumbel-softmax-Distribution/#comments" class="article-comment-link">
          <span class="post-comments-count valine-comment-count" data-xid="/2018/01/28/GANS-for-Sequences-of-Discrete-Elements-with-the-Gumbel-softmax-Distribution/" itemprop="commentCount"></span>
          Comments
        </a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/GANs/" rel="tag">GANs</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Gumbel-softmax%E5%88%86%E5%B8%83/" rel="tag">Gumbel-softmax分布</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2018/03/31/the-numerics-of-gans/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          论文阅读-The Numerics of GANs
        
      </div>
    </a>
  
  
    <a href="/2018/01/21/Text-Generation-using-Generative-Adversarial-Training/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">论文阅读-对抗训练文本生成</div>
    </a>
  
</nav>

  
</article>



  <section id="comments" class="vcomment">

  </section>
</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title"><i class="fas fa-paperclip"></i>&nbsp;&nbsp;分类</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/GANs/">GANs</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/NLP/">NLP</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%BA%BA%E6%96%87/">人文</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%BC%A0%E9%87%8F%E8%AE%A1%E7%AE%97/">张量计算</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%8A%80%E6%9C%AF/">技术</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/">数据库</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/">数据结构</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90/">文本生成</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%AE%97%E6%B3%95/">算法</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/">算法分析</a><span class="category-list-count">1</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title"><i class="fas fa-tags"></i>&nbsp;&nbsp;标签</h3>
    <div class="widget tagcloud">
      <a href="/tags/C%E8%AF%AD%E8%A8%80/" style="font-size: 15px;">C语言</a> <a href="/tags/GANs/" style="font-size: 20px;">GANs</a> <a href="/tags/GRUs/" style="font-size: 10px;">GRUs</a> <a href="/tags/Gumbel-softmax%E5%88%86%E5%B8%83/" style="font-size: 10px;">Gumbel-softmax分布</a> <a href="/tags/LSTMs/" style="font-size: 10px;">LSTMs</a> <a href="/tags/Q%E5%AD%A6%E4%B9%A0/" style="font-size: 10px;">Q学习</a> <a href="/tags/echarts/" style="font-size: 10px;">echarts</a> <a href="/tags/javascript/" style="font-size: 10px;">javascript</a> <a href="/tags/mysql/" style="font-size: 10px;">mysql</a> <a href="/tags/navicat%E8%BD%AF%E4%BB%B6/" style="font-size: 10px;">navicat软件</a> <a href="/tags/pytorch/" style="font-size: 10px;">pytorch</a> <a href="/tags/skip-gram/" style="font-size: 10px;">skip-gram</a> <a href="/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/" style="font-size: 10px;">二叉树</a> <a href="/tags/%E5%BC%A0%E9%87%8F%E6%93%8D%E4%BD%9C/" style="font-size: 10px;">张量操作</a> <a href="/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/" style="font-size: 10px;">强化学习</a> <a href="/tags/%E5%BF%83%E7%90%86%E5%AD%A6/" style="font-size: 10px;">心理学</a> <a href="/tags/%E6%8E%92%E5%BA%8F/" style="font-size: 10px;">排序</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" style="font-size: 10px;">数据结构</a> <a href="/tags/%E7%BA%B3%E4%BB%80%E5%9D%87%E8%A1%A1/" style="font-size: 10px;">纳什均衡</a> <a href="/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/" style="font-size: 10px;">线性代数</a> <a href="/tags/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/" style="font-size: 10px;">语言模型</a> <a href="/tags/%E8%B7%A8%E5%9F%9F/" style="font-size: 10px;">跨域</a> <a href="/tags/%E9%9A%8F%E7%AC%94/" style="font-size: 10px;">随笔</a> <a href="/tags/%E9%9B%B6%E5%92%8C%E5%8D%9A%E5%BC%88/" style="font-size: 10px;">零和博弈</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title"><i class="far fa-folder-open"></i>&nbsp;&nbsp;归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/12/">December 2020</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/10/">October 2020</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/07/">July 2020</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">March 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">January 2018</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">December 2017</a><span class="archive-list-count">1</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title"><i class="far fa-edit"></i>&nbsp;&nbsp;最新</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2020/12/11/echart-question-all/">echarts使用中的跨域问题</a>
          </li>
        
          <li>
            <a href="/2020/12/03/du-shu-bi-ji-shengming-yiyi/">读书笔记(1)</a>
          </li>
        
          <li>
            <a href="/2020/10/15/mysql-navicat/">mysql服务的安装与navicat连接</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner" text-align="center">
      Copyright &copy; 2021 叶飞. All rights reserved.
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">主页</a>
  
    <a href="/archives" class="mobile-nav-link">归档</a>
  
    <a href="/about" class="mobile-nav-link">关于</a>
  
    <a href="/links" class="mobile-nav-link">友链</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  
<script src="https://cdn.jsdelivr.net/npm/valine@1.3.10/dist/Valine.min.js"></script>

<script>
    var GUEST_INFO = ['nick','mail','link'];
    var guest_info = 'nick,mail,link'.split(',').filter(function(item){
        return GUEST_INFO.indexOf(item) > -1
    });
    var notify = 'false' == true;
    var verify = 'false' == true;
    new Valine({
        el: '.vcomment',
        notify: notify,
        verify: verify,
        appId: "2DweflGgmGaECjHfBXXNOlxp-gzGzoHsz",
        appKey: "XHkgm8ia8oCFMaA8dgPLMf9C",
        placeholder: "Just go go",
        pageSize:'10',
        avatar:'mm',
        lang:'zh-cn'
    });
</script>

  </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>